# ğŸ§ª Data Asset Quality Template

> A universal template and framework for ensuring the **quality and integrity** of data assets during migrations, ingestions, and ongoing operations.

---

## âœ¨ Why Use This Template?

In modern data ecosystems, **data moves constantly**. This template helps ensure data **accuracy, completeness, and consistency** by providing:

* âœ… **Standardized Data Validation**
  A consistent methodology for quality checks across all projects.

* ğŸš€ **Accelerated UAT & QC**
  Rapid validation for data migration and ingestion pipelines.

* ğŸ› ï¸ **Robust Design**
  Built with containerization, strong error handling, and distributed PySpark execution.

* ğŸ”Œ **Future-Proofing**
  Easily extend to support new sources, validation types, or DQ frameworks.

* ğŸ” **CI/CD Ready**
  Integrates with GitHub Actions and GitLab CI for automation.

* ğŸ¤ **Team Collaboration**
  Clear structure and docs support knowledge sharing and onboarding.

---

## ğŸš€ Key Features

* ğŸ§© **Configurable Validations**
  YAML-driven rules: schema, row counts, aggregates, checksums.

* ğŸ”Œ **Pluggable Connectors**
  Easily support Teradata, Hive, Delta Lake, SQL Server, PostgreSQL, etc.

* ğŸ” **Data Quality Frameworks**

  * [Great Expectations](https://greatexpectations.io): Declarative validation.
  * [Deequ](https://github.com/awslabs/deequ): Spark-native metrics.

* âš¡ **PySpark-Powered**
  Distributed and scalable data processing.

* ğŸ³ **Containerized Environment**
  Consistent setup with Docker.

* ğŸ“š **Comprehensive Documentation**
  From setup to mapping to report generation.

* ğŸ” **Secure Credential Handling**
  Uses env vars or external secret stores.

* ğŸ““ **Notebook Support**
  Compatible with Marimo and Jupyter for interactive reporting.

* ğŸ› ï¸ **Makefile Driven**
  Centralized commands for developer productivity.

---

## âš™ï¸ Technologies Used

* Python 3.9+
* PySpark
* [uv](https://github.com/astral-sh/uv)
* Docker
* YAML
* Great Expectations (optional)
* Deequ (optional)
* Jupyter / Marimo (optional)
* `make`
* GitHub Actions / GitLab CI

---

## ğŸ—ï¸ Repository Structure

```
data-asset-quality-template/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â”œâ”€â”€ build_and_push_docker.yml # GitHub Actions: Build & push Docker image
â”‚       â””â”€â”€ validate_data.yml     # GitHub Actions: Orchestrate validation run
â”œâ”€â”€ .gitlab-ci.yml                # GitLab CI/CD configuration
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ environments/             # Environment-specific configuration (dev, UAT, prod)
â”‚   â”‚   â”œâ”€â”€ dev.yaml
â”‚   â”‚   â”œâ”€â”€ uat.yaml
â”‚   â”‚   â””â”€â”€ prod.yaml
â”‚   â”œâ”€â”€ connectors.yaml           # Generic DB connection details (placeholders)
â”‚   â”œâ”€â”€ validation_rules.yaml     # Centralized definition of validation rules
â”‚   â””â”€â”€ table_mappings.yaml       # Generic source-to-target table/column mappings
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_data/              # Optional: Anonymized sample data for template dev/testing
â”‚       â”œâ”€â”€ source_sample.csv
â”‚       â””â”€â”€ target_sample.csv
â”œâ”€â”€ docs/                         # Comprehensive documentation and guides
â”‚   â”œâ”€â”€ TEMPLATE_GUIDE.md         # *** CRITICAL: How to use this repo as a template ***
â”‚   â”œâ”€â”€ PROJECT_SETUP.md          # Guide for setting up a new project from this template
â”‚   â”œâ”€â”€ UAT_Process_Guide.md      # General guide for UAT process
â”‚   â”œâ”€â”€ Data_Validation_Methods.md# Explanation of template's validation methods
â”‚   â”œâ”€â”€ Data_Type_Mapping_Guide.md# Guide for adapting data type mappings
â”‚   â”œâ”€â”€ Discrepancy_Log_Template.md# Template for logging issues
â”‚   â”œâ”€â”€ Known_Issues_Template.md  # Template for documenting accepted deviations
â”‚   â””â”€â”€ Reporting_Templates/      # Templates for final UAT reports
â”‚       â””â”€â”€ UAT_Report_Template.docx
â”œâ”€â”€ expectations/                 # For Great Expectations or Deequ expectations
â”‚   â”œâ”€â”€ deequ_expectations/
â”‚   â”‚   â”œâ”€â”€ my_table_expectations.py # Deequ expectation definitions
â”‚   â”‚   â””â”€â”€ another_table_expectations.py
â”‚   â””â”€â”€ great_expectations/
â”‚       â”œâ”€â”€ checkpoints/
â”‚       â”œâ”€â”€ expectations/
â”‚       â”‚   â””â”€â”€ my_table_suite.json
â”‚       â””â”€â”€ uncommitted/          # Uncommitted data docs, validation results, etc.
â”œâ”€â”€ notebooks/                    # Interactive notebooks (Marimo, Jupyter, etc.)
â”‚   â”œâ”€â”€ template_eda.py           # Example EDA (can be run by Marimo or Python)
â”‚   â”œâ”€â”€ template_validation_report.py # Example validation report (Marimo/Python)
â”‚   â””â”€â”€ template_expectation_profiling.py # Example profiling (Marimo/Python)
â”œâ”€â”€ src/                          # All core Python/PySpark logic
â”‚   â”œâ”€â”€ connectors/               # Abstracted database connectors
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_connector.py
â”‚   â”‚   â”œâ”€â”€ jdbc_connector.py     # Generic JDBC implementation
â”‚   â”‚   â””â”€â”€ hive_connector.py     # Generic Hive/Hudi/Delta Lake connector
â”‚   â”œâ”€â”€ validators/               # Modular, generic validation logic
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_validator.py
â”‚   â”‚   â”œâ”€â”€ schema_validator.py
â”‚   â”‚   â”œâ”€â”€ count_validator.py
â”‚   â”‚   â”œâ”€â”€ aggregation_validator.py
â”‚   â”‚   â””â”€â”€ checksum_validator.py
â”‚   â”œâ”€â”€ data_expectations/        # Integration with Great Expectations/Deequ
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ge_integration.py
â”‚   â”‚   â””â”€â”€ deequ_integration.py
â”‚   â”œâ”€â”€ reports/                  # Report generation modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ html_reporter.py
â”‚   â”œâ”€â”€ main.py                   # Orchestration script
â”‚   â””â”€â”€ utils.py                  # Common utilities (config parsing, logging, error handling)
â”œâ”€â”€ tests/                        # Unit and integration tests for validation logic
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_connectors.py
â”‚   â”‚   â””â”€â”€ test_validators.py
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_e2e_validation.py # Mini-end-to-end test with sample data
â”œâ”€â”€ Dockerfile                    # Docker build instructions
â”œâ”€â”€ entrypoint.sh                 # Script executed by Docker container
â”œâ”€â”€ Makefile                      # Centralized commands for development and operations
â”œâ”€â”€ pyproject.toml                # Project metadata and uv dependency configuration
â”œâ”€â”€ .dockerignore                 # Files to ignore when building Docker image
â”œâ”€â”€ .gitignore                    # Files to ignore in Git
â”œâ”€â”€ README.md                     # This file
â””â”€â”€ LICENSE
```

---

## ğŸš€ Getting Started

### ğŸ§ª Create a New Project from the Template

**GitHub**
Click the **"Use this template"** button on the repository page.

**GitLab**
Create a new project â†’ *Import Project* â†’ *Repo by URL*.

**Manual Setup**

```bash
git clone https://github.com/pesnik/data-asset-quality-template.git <your-new-project-name>
cd <your-new-project-name>
rm -rf .git
git init -b main
```

ğŸ‘‰ See `docs/TEMPLATE_GUIDE.md` for:

* Source/target DB config
* Validation rules setup
* Secure credentials management
* CI/CD pipeline integration

---

## ğŸ³ Local Development (Docker + uv)

### ğŸ”§ Prerequisites

* Docker Desktop
* Git
* Python 3.9+
* `make`
* `uv` (install via `pip install uv`)

### ğŸ“¦ Install Python Dependencies

```bash
make install-deps-local
```

### ğŸ—ï¸ Build Docker Image

```bash
make build-docker
```

### âœ… Run Validations

```bash
make run-validation-local VALIDATION_ENV=uat \
  TERADATA_HOST="your_td_host" \
  TERADATA_PORT="your_td_port" \
  TERADATA_USER="your_td_user" \
  TERADATA_PASSWORD="your_td_password" \
  CLOUD_HIVE_HOST="your_cloud_host" \
  CLOUD_HIVE_PORT="your_cloud_port" \
  CLOUD_HIVE_USER="your_cloud_user" \
  CLOUD_HIVE_PASSWORD="your_cloud_password"
```

> Use secrets manager for production credentials.

---

## ğŸ““ Interactive Notebooks

### Run Marimo or Jupyter notebooks:

```bash
make run-notebook NOTEBOOK_PATH=notebooks/template_validation_report.py
# OR
make run-marimo MARIMO_APP=template_validation_report.py
# OR
make run-jupyter NOTEBOOK_PATH=notebooks/my_jupyter_report.ipynb
```

> *Add `run-jupyter` to the `Makefile` and install Jupyter if needed.*

---

## ğŸ“ˆ Running Validations in CI/CD

### GitHub Actions

Configured in `.github/workflows/`

### GitLab CI

Configured in `.gitlab-ci.yml`

#### CI/CD Pipeline Flow:

1. Build Docker image
2. Push to registry
3. Run validation inside container
4. Save output as artifact

---

## ğŸ“Š Reporting

* Outputs visible in logs & artifacts
* Use `src/reports/` to generate HTML/CSV reports
* Use `notebooks/` for EDA dashboards via Marimo/Jupyter

---

## ğŸ¤ Contributing

We welcome contributions and improvements!
*Contribution guide coming soon in `CONTRIBUTING.md`.*

---

## ğŸ“„ License

This project is licensed under the **MIT License**.
See [`LICENSE`](./LICENSE) for more information.
